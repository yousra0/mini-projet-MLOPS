.PHONY: install train evaluate-staging evaluate-production test lint data setup notebook run-api test-api deploy clean build run list login push start stop logs notify full-pipeline

# ğŸ“Œ DÃ©finitions des variables
PYTHON=python3
ENV_NAME=venv
REQUIREMENTS=requirements.txt

DATA_PATH=/home/yousra/yousra_chaieb_ml_project/churn-bigml-80.csv
TEST_DATA_PATH=/home/yousra/yousra_chaieb_ml_project/churn-bigml-20.csv
MODEL_DIR=models
MODEL_PATH=$(MODEL_DIR)/random_forest_model.pkl

# ğŸš€ Ã‰tape 1 : Installation des dÃ©pendances
install:
	@echo "ğŸ”§ CrÃ©ation de l'environnement virtuel et installation des dÃ©pendances..."
	$(PYTHON) -m venv $(ENV_NAME)
	. $(ENV_NAME)/bin/activate && pip install -r $(REQUIREMENTS)

# ğŸš€ Ã‰tape 2 : EntraÃ®nement du modÃ¨le et enregistrement en Staging
train:
	@echo "ğŸ“‚ CrÃ©ation du dossier pour le modÃ¨le..."
	mkdir -p $(MODEL_DIR)
	. $(ENV_NAME)/bin/activate && python3 main.py --data $(DATA_PATH) --train --save $(MODEL_PATH) --stage Staging

# ğŸš€ Ã‰tape 3 : Ã‰valuation du modÃ¨le
## ğŸ”¹ Ã‰valuation en Staging
evaluate-staging:
	. $(ENV_NAME)/bin/activate && python3 main.py --data $(DATA_PATH) --evaluate --stage Staging

## ğŸ”¹ Passer un modÃ¨le en Production
evaluate-production:
	. $(ENV_NAME)/bin/activate && python3 main.py --data $(DATA_PATH) --evaluate --stage Production

# ğŸš€ Ã‰tape 4 : Tests et vÃ©rifications
## ğŸ”¹ ExÃ©cution des tests unitaires
test:
	@echo "ğŸ§ª ExÃ©cution des tests unitaires..."
	. $(ENV_NAME)/bin/activate && pytest tests/

## ğŸ”¹ VÃ©rification du code avec Flake8
lint:
	@echo "ğŸ” VÃ©rification du code avec flake8..."
	. $(ENV_NAME)/bin/activate && flake8 .

# ğŸš€ Ã‰tape 5 : PrÃ©paration des donnÃ©es
data:
	@echo "ğŸ“‚ PrÃ©paration des donnÃ©es..."
	. $(ENV_NAME)/bin/activate && python /home/yousra/yousra_chaieb_ml_project/model_pipeline.py

# ğŸš€ Ã‰tape 6 : Configuration initiale
setup: install
	@echo "âœ… Configuration terminÃ©e."

# ğŸš€ Ã‰tape 7 : ExÃ©cution des notebooks
notebook:
	@echo "ğŸ“– DÃ©marrage de Jupyter Notebook..."
	. $(ENV_NAME)/bin/activate && jupyter notebook

# ğŸš€ Ã‰tape 8 : ExÃ©cution et test de l'API FastAPI
## ğŸ”¹ Lancer l'API
run-api:
	uvicorn app:app --reload --host 0.0.0.0 --port 8001

## ğŸ”¹ Tester l'API via Swagger
test-api:
	@echo "ğŸŒ Ouvrir l'interface Swagger Ã  l'adresse http://127.0.0.1:8001/docs"
	uvicorn app:app --reload --host 127.0.0.1 --port 8001

# ğŸš€ Ã‰tape 9 : DÃ©ploiement
deploy:
	@echo "ğŸš€ DÃ©ploiement du modÃ¨le..."
	uvicorn app:app --host 0.0.0.0 --port 8001 --workers 4

# ğŸš€ Ã‰tape 10 : Nettoyage de l'environnement
clean:
	@echo "ğŸ§¹ Nettoyage des fichiers temporaires..."
	rm -rf $(ENV_NAME) __pycache__ *.pyc *.pyo .pytest_cache .mypy_cache

# ğŸš€ Ã‰tape 11 : Gestion Docker
## ğŸ”¹ Construire lâ€™image Docker
build:
	docker build -t yousra_chaieb_4ds4_mlops .

## ğŸ”¹ ExÃ©cuter le conteneur
run:
	docker run -p 8000:8000 yousra_chaieb_4ds4_mlops

## ğŸ”¹ Lister les images Docker
list:
	docker images

## ğŸ”¹ Se connecter Ã  Docker Hub
login:
	docker login

## ğŸ”¹ Pousser lâ€™image sur Docker Hub
push:
	docker tag yousra_chaieb_4ds4_mlops yousrachaieb/fastapi-mlflow-app:v1
	docker push yousrachaieb/fastapi-mlflow-app:v1

# ğŸš€ Ã‰tape 12 : Gestion des services avec Docker Compose
## ğŸ”¹ DÃ©marrer MLflow et FastAPI
start:
	docker-compose up -d
	mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000
	uvicorn app:app --host 0.0.0.0 --port 8000

## ğŸ”¹ ArrÃªter les services
stop:
	docker-compose down

## ğŸ”¹ Afficher les logs des services
logs:
	docker-compose logs -f

# ğŸš€ Ã‰tape 13 : Partie bonus - Notification par e-mail
EMAIL_NOTIFICATION_SCRIPT=send_email.py

# ğŸ”¹ Pipeline complÃ¨te avec notification
full-pipeline: install lint data train test notify

# ğŸ”¹ Envoi d'une notification
notify:
	@echo "âœ… Pipeline terminÃ© avec succÃ¨s !" 
	. $(ENV_NAME)/bin/activate && python send_email.py
